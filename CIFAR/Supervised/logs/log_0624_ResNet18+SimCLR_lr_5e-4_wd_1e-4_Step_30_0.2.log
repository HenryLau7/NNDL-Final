nohup: ignoring input
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with deit.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_tiny_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with deit.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_small_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with deit.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_base_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with deit.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with deit.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with deit.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with deit.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_base_patch16_384(pretrained=False, **kwargs):
/root/liuyuanye/NNDL/Final/CIFAR/deit.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with deit.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):
/root/miniconda3/envs/py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
{
    "datapath": "../data/",
    "logpath": "./logs/",
    "batch_size": 512,
    "epoch": 100,
    "seed": 43,
    "date": "0625",
    "plot": true,
    "num_classes": 100,
    "opt": "AdamW",
    "learning_rate": 0.0005,
    "weight_decay": 0.0001,
    "pretrained": true,
    "device_id": 0,
    "dropout": true,
    "cutout": true,
    "cutmix": false,
    "model": "ResNet18+SimCLR",
    "comment": "StepLR_30_0.2"
}
2024-06-25 14:30:03
Epoch:0, Loss:4.568141757225503, Acc:3.082, LR:0.0005
Epoch:1, Loss:4.492911241492447, Acc:7.098, LR:0.0005
Epoch:2, Loss:4.424397103640498, Acc:10.17, LR:0.0005
Epoch:3, Loss:4.361744744437082, Acc:12.02, LR:0.0005
Epoch:4, Loss:4.304290717961837, Acc:13.06, LR:0.0005
Validation: Loss:4.364445352554322, Acc:10.47
Best model updated!
Epoch:5, Loss:4.2525264730258865, Acc:14.096, LR:0.0005
Epoch:6, Loss:4.204199070833167, Acc:14.714, LR:0.0005
Epoch:7, Loss:4.158718177250454, Acc:15.084, LR:0.0005
Epoch:8, Loss:4.116948332105364, Acc:15.398, LR:0.0005
Epoch:9, Loss:4.078746469653383, Acc:15.866, LR:0.0005
Validation: Loss:4.195631766319275, Acc:12.56
Best model updated!
Epoch:10, Loss:4.043113255987362, Acc:15.776, LR:0.0005
Epoch:11, Loss:4.010900536362006, Acc:16.274, LR:0.0005
Epoch:12, Loss:3.978591490765007, Acc:16.598, LR:0.0005
Epoch:13, Loss:3.9495842456817627, Acc:16.78, LR:0.0005
Epoch:14, Loss:3.9213187889176973, Acc:16.808, LR:0.0005
Validation: Loss:4.0744781494140625, Acc:13.7
Best model updated!
Epoch:15, Loss:3.8960904710146846, Acc:16.926, LR:0.0005
Epoch:16, Loss:3.8735502690685037, Acc:17.042, LR:0.0005
Epoch:17, Loss:3.8508832308710836, Acc:17.17, LR:0.0005
Epoch:18, Loss:3.8294873991791083, Acc:17.582, LR:0.0005
Epoch:19, Loss:3.8102398940495084, Acc:17.244, LR:0.0005
Validation: Loss:3.9825295090675352, Acc:14.48
Best model updated!
Epoch:20, Loss:3.7885559651316427, Acc:17.686, LR:0.0005
Epoch:21, Loss:3.772899321147374, Acc:17.756, LR:0.0005
Epoch:22, Loss:3.7562214063138377, Acc:17.858, LR:0.0005
Epoch:23, Loss:3.7409093720572337, Acc:17.896, LR:0.0005
Epoch:24, Loss:3.726918495431238, Acc:18.03, LR:0.0005
Validation: Loss:3.914092457294464, Acc:14.96
Best model updated!
Epoch:25, Loss:3.7132431122721457, Acc:18.108, LR:0.0005
Epoch:26, Loss:3.6976225278815447, Acc:18.39, LR:0.0005
Epoch:27, Loss:3.6863974089525184, Acc:18.51, LR:0.0005
Epoch:28, Loss:3.6722468502667485, Acc:18.3, LR:0.0005
Epoch:29, Loss:3.6590397601224938, Acc:18.604, LR:0.0001
Validation: Loss:3.8563174843788146, Acc:15.39
Best model updated!
Epoch:30, Loss:3.655615232428726, Acc:18.44, LR:0.0001
Epoch:31, Loss:3.65306032677086, Acc:18.48, LR:0.0001
Epoch:32, Loss:3.6463464036279793, Acc:18.672, LR:0.0001
Epoch:33, Loss:3.6498682620574017, Acc:18.428, LR:0.0001
Epoch:34, Loss:3.6446907544622618, Acc:18.462, LR:0.0001
Validation: Loss:3.8484855771064757, Acc:15.46
Best model updated!
Epoch:35, Loss:3.6449738230024065, Acc:18.342, LR:0.0001
Epoch:36, Loss:3.645801702324225, Acc:18.602, LR:0.0001
Epoch:37, Loss:3.639106490174118, Acc:18.59, LR:0.0001
Epoch:38, Loss:3.6364226657517102, Acc:18.612, LR:0.0001
Epoch:39, Loss:3.634890770425602, Acc:18.842, LR:0.0001
Validation: Loss:3.8346707105636595, Acc:15.41
Epoch:40, Loss:3.6346155332059276, Acc:18.738, LR:0.0001
Epoch:41, Loss:3.6337924952409706, Acc:18.56, LR:0.0001
Epoch:42, Loss:3.6374187931722526, Acc:18.574, LR:0.0001
Epoch:43, Loss:3.6276710544313704, Acc:18.702, LR:0.0001
Epoch:44, Loss:3.628992428584975, Acc:18.696, LR:0.0001
Validation: Loss:3.8275392293930053, Acc:15.58
Best model updated!
Epoch:45, Loss:3.623859931011589, Acc:18.71, LR:0.0001
Epoch:46, Loss:3.6222822130942833, Acc:18.91, LR:0.0001
Epoch:47, Loss:3.6197069080508486, Acc:18.884, LR:0.0001
Epoch:48, Loss:3.619012494476474, Acc:18.864, LR:0.0001
Epoch:49, Loss:3.6126140623676535, Acc:18.91, LR:0.0001
Validation: Loss:3.8175432801246645, Acc:15.55
Epoch:50, Loss:3.6122655163005906, Acc:18.808, LR:0.0001
Epoch:51, Loss:3.6108655905237, Acc:19.054, LR:0.0001
Epoch:52, Loss:3.611807171179324, Acc:18.736, LR:0.0001
Epoch:53, Loss:3.6085661965973523, Acc:18.922, LR:0.0001
Epoch:54, Loss:3.6053487330066916, Acc:19.014, LR:0.0001
Validation: Loss:3.8123086214065554, Acc:15.53
Epoch:55, Loss:3.6064401937990773, Acc:18.824, LR:0.0001
Epoch:56, Loss:3.604914061877192, Acc:18.882, LR:0.0001
Epoch:57, Loss:3.6024598710390987, Acc:18.888, LR:0.0001
Epoch:58, Loss:3.60034078481246, Acc:18.878, LR:0.0001
Epoch:59, Loss:3.600410045409689, Acc:18.83, LR:2e-05
Validation: Loss:3.804659402370453, Acc:15.55
Epoch:60, Loss:3.596105804248732, Acc:19.0, LR:2e-05
Epoch:61, Loss:3.599314207933387, Acc:18.998, LR:2e-05
Epoch:62, Loss:3.5968355353997676, Acc:19.094, LR:2e-05
Epoch:63, Loss:3.5939836453418343, Acc:18.936, LR:2e-05
Epoch:64, Loss:3.591387965241257, Acc:18.996, LR:2e-05
Validation: Loss:3.8038277983665467, Acc:15.56
Epoch:65, Loss:3.5964369652222614, Acc:18.928, LR:2e-05
Epoch:66, Loss:3.595879841823967, Acc:19.116, LR:2e-05
Epoch:67, Loss:3.5930661133357455, Acc:18.948, LR:2e-05
Epoch:68, Loss:3.5935207167450263, Acc:18.988, LR:2e-05
Epoch:69, Loss:3.593499023087171, Acc:18.87, LR:2e-05
Validation: Loss:3.7997764110565186, Acc:15.57
Epoch:70, Loss:3.5946878754362768, Acc:18.994, LR:2e-05
Epoch:71, Loss:3.5946462738270664, Acc:18.932, LR:2e-05
Epoch:72, Loss:3.5931866071662126, Acc:18.766, LR:2e-05
Epoch:73, Loss:3.5948818021891067, Acc:18.888, LR:2e-05
Epoch:74, Loss:3.5935090439660207, Acc:18.934, LR:2e-05
Validation: Loss:3.8002706170082092, Acc:15.54
Epoch:75, Loss:3.595664902609222, Acc:18.768, LR:2e-05
Epoch:76, Loss:3.591520589225146, Acc:19.082, LR:2e-05
Epoch:77, Loss:3.593090828584165, Acc:18.868, LR:2e-05
Epoch:78, Loss:3.597165589429894, Acc:18.808, LR:2e-05
Epoch:79, Loss:3.590947007646366, Acc:19.056, LR:2e-05
Validation: Loss:3.7953885912895204, Acc:15.55
Epoch:80, Loss:3.5912257676221886, Acc:18.98, LR:2e-05
Epoch:81, Loss:3.5896211935549367, Acc:18.948, LR:2e-05
Epoch:82, Loss:3.5902237575881335, Acc:18.914, LR:2e-05
Epoch:83, Loss:3.589180958514311, Acc:19.026, LR:2e-05
Epoch:84, Loss:3.589419523063971, Acc:19.066, LR:2e-05
Validation: Loss:3.7933496832847595, Acc:15.65
Best model updated!
Epoch:85, Loss:3.588789470341741, Acc:18.878, LR:2e-05
Epoch:86, Loss:3.589972213822968, Acc:18.94, LR:2e-05
Epoch:87, Loss:3.5859308826680087, Acc:19.078, LR:2e-05
Epoch:88, Loss:3.5908221079378713, Acc:19.002, LR:2e-05
Epoch:89, Loss:3.5867525022857043, Acc:19.138, LR:4.000000000000001e-06
Validation: Loss:3.7915241837501528, Acc:15.65
Epoch:90, Loss:3.591005877572663, Acc:18.88, LR:4.000000000000001e-06
Epoch:91, Loss:3.585994387159542, Acc:18.946, LR:4.000000000000001e-06
Epoch:92, Loss:3.5851455488983466, Acc:18.94, LR:4.000000000000001e-06
Epoch:93, Loss:3.587609188897269, Acc:19.022, LR:4.000000000000001e-06
Epoch:94, Loss:3.586669634799568, Acc:19.072, LR:4.000000000000001e-06
Validation: Loss:3.7938421249389647, Acc:15.65
Epoch:95, Loss:3.5918059154432647, Acc:18.968, LR:4.000000000000001e-06
Epoch:96, Loss:3.5863502998741303, Acc:18.848, LR:4.000000000000001e-06
Epoch:97, Loss:3.586872477920688, Acc:18.916, LR:4.000000000000001e-06
Epoch:98, Loss:3.588468004246147, Acc:18.874, LR:4.000000000000001e-06
Epoch:99, Loss:3.5908939984379984, Acc:19.052, LR:4.000000000000001e-06
Validation: Loss:3.794575238227844, Acc:15.58
Test: Acc:15.65
